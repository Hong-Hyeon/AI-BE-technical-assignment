"""
ë²¡í„° ê²€ìƒ‰ íŒ©í† ë¦¬ - PostgreSQL pgvectorë¥¼ í™œìš©í•œ ì˜ë¯¸ì  ê²€ìƒ‰ êµ¬í˜„
ë°°ì¹˜ ì„ë² ë”© ì²˜ë¦¬ë¡œ ìµœì í™”ë¨
"""
import os
from typing import List, Dict, Any, Optional, Tuple
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from langchain_openai import OpenAIEmbeddings
from dotenv import load_dotenv

from models.company import Company, CompanyNews
from services.batch_embedding_service import BatchEmbeddingService, EmbeddingRequest
from config.logging_config import get_api_logger

load_dotenv()


class VectorSearchEngine:
    """pgvector ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰ ì—”ì§„ (ë°°ì¹˜ ìµœì í™”)"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.logger = get_api_logger()
        
        # ë°°ì¹˜ ì„ë² ë”© ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.batch_embedding_service = BatchEmbeddingService(
            model="text-embedding-3-small",
            max_batch_size=50,  # ë²¡í„° ê²€ìƒ‰ì— ìµœì í™”ëœ ë°°ì¹˜ í¬ê¸°
            cache_enabled=True
        )
        
        # ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ê°œë³„ ì„ë² ë”© ëª¨ë¸
        self.embeddings_model = OpenAIEmbeddings(
            model="text-embedding-3-small",
            api_key=os.getenv("OPENAI_API_KEY")
        )
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        self.engine = create_engine(
            os.getenv("DATABASE_URL")
        )
        
        Session = sessionmaker(bind=self.engine)
        self.session = Session()
    
    def search_similar_companies(
        self, 
        query: str, 
        limit: int = 5, 
        similarity_threshold: float = 0.3
    ) -> List[Dict[str, Any]]:
        """ìœ ì‚¬í•œ íšŒì‚¬ ê²€ìƒ‰ (ê°œë³„ ì¿¼ë¦¬ìš©)"""
        try:
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self.embeddings_model.embed_query(query)
            
            # ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰ (ë²¡í„° íƒ€ì…ìœ¼ë¡œ ëª…ì‹œì  ìºìŠ¤íŒ…)
            results = self.session.execute(
                text("""
                    SELECT 
                        id,
                        name,
                        data,
                        1 - (embedding <=> CAST(:query_embedding AS vector)) as similarity
                    FROM company 
                    WHERE embedding IS NOT NULL
                        AND 1 - (embedding <=> CAST(:query_embedding AS vector)) > :similarity_threshold
                    ORDER BY embedding <=> CAST(:query_embedding AS vector)
                    LIMIT :limit
                """),
                {
                    "query_embedding": query_embedding,
                    "similarity_threshold": similarity_threshold,
                    "limit": limit
                }
            ).fetchall()
            
            return [
                {
                    "id": row.id,
                    "name": row.name,
                    "data": row.data,
                    "similarity": float(row.similarity)
                }
                for row in results
            ]
            
        except Exception as e:
            self.logger.error(f"íšŒì‚¬ ë²¡í„° ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def search_similar_news(
        self, 
        query: str, 
        limit: int = 10, 
        similarity_threshold: float = 0.3,
        company_ids: Optional[List[int]] = None
    ) -> List[Dict[str, Any]]:
        """ìœ ì‚¬í•œ ë‰´ìŠ¤ ê²€ìƒ‰ (ê°œë³„ ì¿¼ë¦¬ìš©)"""
        try:
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self.embeddings_model.embed_query(query)
            
            # íŠ¹ì • íšŒì‚¬ë“¤ë¡œ í•„í„°ë§í•˜ëŠ” ê²½ìš°
            company_filter = ""
            params = {
                "query_embedding": query_embedding,
                "similarity_threshold": similarity_threshold,
                "limit": limit
            }
            
            if company_ids:
                company_filter = "AND cn.company_id = ANY(:company_ids)"
                params["company_ids"] = company_ids
            
            # ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰ (ë²¡í„° íƒ€ì…ìœ¼ë¡œ ëª…ì‹œì  ìºìŠ¤íŒ…)
            results = self.session.execute(
                text(f"""
                    SELECT 
                        cn.id,
                        cn.title,
                        cn.news_date,
                        cn.original_link,
                        c.name as company_name,
                        c.id as company_id,
                        1 - (cn.embedding <=> CAST(:query_embedding AS vector)) as similarity
                    FROM company_news cn
                    JOIN company c ON cn.company_id = c.id
                    WHERE cn.embedding IS NOT NULL
                        AND 1 - (cn.embedding <=> CAST(:query_embedding AS vector)) > :similarity_threshold
                        {company_filter}
                    ORDER BY cn.embedding <=> CAST(:query_embedding AS vector)
                    LIMIT :limit
                """),
                params
            ).fetchall()
            
            return [
                {
                    "id": row.id,
                    "title": row.title,
                    "news_date": row.news_date,
                    "original_link": row.original_link,
                    "company_name": row.company_name,
                    "company_id": row.company_id,
                    "similarity": float(row.similarity)
                }
                for row in results
            ]
            
        except Exception as e:
            self.logger.error(f"ë‰´ìŠ¤ ë²¡í„° ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    async def batch_search_companies(
        self,
        queries: List[str],
        limit: int = 5,
        similarity_threshold: float = 0.3
    ) -> Dict[str, List[Dict[str, Any]]]:
        """
        ë°°ì¹˜ë¡œ ì—¬ëŸ¬ ì¿¼ë¦¬ì— ëŒ€í•œ íšŒì‚¬ ê²€ìƒ‰ ìˆ˜í–‰.
        
        Returns:
            Dict mapping query -> search results
        """
        if not queries:
            return {}
        
        self.logger.info(f"ğŸ” Batch company search for {len(queries)} queries")
        
        try:
            # ë°°ì¹˜ ì„ë² ë”© ìƒì„±
            embedding_requests = [
                EmbeddingRequest(
                    id=f"company_query_{i}",
                    text=query,
                    priority=2,
                    metadata={"type": "company_search", "index": i}
                )
                for i, query in enumerate(queries)
            ]
            
            embedding_results = await self.batch_embedding_service.get_embeddings_batch(
                embedding_requests, use_cache=True
            )
            
            # ê° ì„ë² ë”©ìœ¼ë¡œ ê²€ìƒ‰ ìˆ˜í–‰
            batch_results = {}
            total_db_queries = 0
            
            for result in embedding_results:
                original_index = int(result.id.split("_")[-1])
                query = queries[original_index]
                
                # ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰
                db_results = self.session.execute(
                    text("""
                        SELECT 
                            id,
                            name,
                            data,
                            1 - (embedding <=> CAST(:query_embedding AS vector)) as similarity
                        FROM company 
                        WHERE embedding IS NOT NULL
                            AND 1 - (embedding <=> CAST(:query_embedding AS vector)) > :similarity_threshold
                        ORDER BY embedding <=> CAST(:query_embedding AS vector)
                        LIMIT :limit
                    """),
                    {
                        "query_embedding": result.embedding,
                        "similarity_threshold": similarity_threshold,
                        "limit": limit
                    }
                ).fetchall()
                
                batch_results[query] = [
                    {
                        "id": row.id,
                        "name": row.name,
                        "data": row.data,
                        "similarity": float(row.similarity)
                    }
                    for row in db_results
                ]
                total_db_queries += 1
            
            # ë°°ì¹˜ ì²˜ë¦¬ í†µê³„ ë¡œê¹…
            embedding_stats = self.batch_embedding_service.get_service_stats()
            self.logger.info(
                f"âœ… Batch company search completed | "
                f"Queries: {len(queries)} | DB searches: {total_db_queries} | "
                f"Embedding cost: ${embedding_stats['total_cost']:.6f}"
            )
            
            return batch_results
            
        except Exception as e:
            self.logger.error(f"ë°°ì¹˜ íšŒì‚¬ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return {query: [] for query in queries}
    
    async def batch_search_news(
        self,
        queries: List[str],
        limit: int = 10,
        similarity_threshold: float = 0.3,
        company_ids: Optional[List[int]] = None
    ) -> Dict[str, List[Dict[str, Any]]]:
        """
        ë°°ì¹˜ë¡œ ì—¬ëŸ¬ ì¿¼ë¦¬ì— ëŒ€í•œ ë‰´ìŠ¤ ê²€ìƒ‰ ìˆ˜í–‰.
        
        Returns:
            Dict mapping query -> search results
        """
        if not queries:
            return {}
        
        self.logger.info(f"ğŸ“° Batch news search for {len(queries)} queries")
        
        try:
            # ë°°ì¹˜ ì„ë² ë”© ìƒì„±
            embedding_requests = [
                EmbeddingRequest(
                    id=f"news_query_{i}",
                    text=query,
                    priority=2,
                    metadata={"type": "news_search", "index": i}
                )
                for i, query in enumerate(queries)
            ]
            
            embedding_results = await self.batch_embedding_service.get_embeddings_batch(
                embedding_requests, use_cache=True
            )
            
            # ê° ì„ë² ë”©ìœ¼ë¡œ ê²€ìƒ‰ ìˆ˜í–‰
            batch_results = {}
            total_db_queries = 0
            
            # íšŒì‚¬ í•„í„° ì„¤ì •
            company_filter = ""
            base_params = {
                "similarity_threshold": similarity_threshold,
                "limit": limit
            }
            
            if company_ids:
                company_filter = "AND cn.company_id = ANY(:company_ids)"
                base_params["company_ids"] = company_ids
            
            for result in embedding_results:
                original_index = int(result.id.split("_")[-1])
                query = queries[original_index]
                
                # íŒŒë¼ë¯¸í„°ì— ì„ë² ë”© ì¶”ê°€
                params = {**base_params, "query_embedding": result.embedding}
                
                # ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰
                db_results = self.session.execute(
                    text(f"""
                        SELECT 
                            cn.id,
                            cn.title,
                            cn.news_date,
                            cn.original_link,
                            c.name as company_name,
                            c.id as company_id,
                            1 - (cn.embedding <=> CAST(:query_embedding AS vector)) as similarity
                        FROM company_news cn
                        JOIN company c ON cn.company_id = c.id
                        WHERE cn.embedding IS NOT NULL
                            AND 1 - (cn.embedding <=> CAST(:query_embedding AS vector)) > :similarity_threshold
                            {company_filter}
                        ORDER BY cn.embedding <=> CAST(:query_embedding AS vector)
                        LIMIT :limit
                    """),
                    params
                ).fetchall()
                
                batch_results[query] = [
                    {
                        "id": row.id,
                        "title": row.title,
                        "news_date": row.news_date,
                        "original_link": row.original_link,
                        "company_name": row.company_name,
                        "company_id": row.company_id,
                        "similarity": float(row.similarity)
                    }
                    for row in db_results
                ]
                total_db_queries += 1
            
            # ë°°ì¹˜ ì²˜ë¦¬ í†µê³„ ë¡œê¹…
            embedding_stats = self.batch_embedding_service.get_service_stats()
            self.logger.info(
                f"âœ… Batch news search completed | "
                f"Queries: {len(queries)} | DB searches: {total_db_queries} | "
                f"Embedding cost: ${embedding_stats['total_cost']:.6f}"
            )
            
            return batch_results
            
        except Exception as e:
            self.logger.error(f"ë°°ì¹˜ ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return {query: [] for query in queries}
    
    async def search_talent_related_context(
        self, 
        talent_data: Dict[str, Any],
        company_limit: int = 5, 
        news_limit: int = 10
    ) -> Dict[str, Any]:
        """
        ìµœì í™”ëœ ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì¸ì¬ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰.
        """
        context = {
            "companies": [],
            "news": [],
            "search_queries": [],
            "metadata": {
                "total_queries": 0,
                "embedding_cache_hits": 0,
                "total_cost": 0.0
            }
        }
        
        try:
            # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            all_queries = []
            
            # êµìœ¡ ê¸°ë°˜ ê²€ìƒ‰ ì¿¼ë¦¬
            education_queries = []
            for edu in talent_data.get("educations", []):
                query = f"{edu.get('school_name', '')} {edu.get('field_of_study', '')} ì¡¸ì—…ìƒ ì·¨ì—… ë™í–¥"
                if query.strip():
                    education_queries.append(query)
            
            # ê²½ë ¥ ê¸°ë°˜ ê²€ìƒ‰ ì¿¼ë¦¬
            position_queries = []
            for pos in talent_data.get("positions", []):
                query = f"{pos.get('company_name', '')} {pos.get('title', '')} ì§ë¬´ ê²½í—˜"
                if query.strip():
                    position_queries.append(query)
            
            # ìŠ¤í‚¬ ê¸°ë°˜ ê²€ìƒ‰ ì¿¼ë¦¬
            skills = talent_data.get("skills", [])
            if skills:
                skill_query = f"{' '.join(skills[:5])} ê¸°ìˆ  ì „ë¬¸ê°€ íšŒì‚¬"
                position_queries.append(skill_query)
            
            all_queries = education_queries + position_queries
            context["search_queries"] = all_queries
            context["metadata"]["total_queries"] = len(all_queries)
            
            if not all_queries:
                self.logger.warning("ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return context
            
            # ë°°ì¹˜ ê²€ìƒ‰ ìˆ˜í–‰
            self.logger.info(f"ğŸš€ Starting optimized batch search for {len(all_queries)} queries")
            
            # íšŒì‚¬ì™€ ë‰´ìŠ¤ë¥¼ ë³‘ë ¬ë¡œ ê²€ìƒ‰
            import asyncio
            
            company_results_task = self.batch_search_companies(
                all_queries, limit=company_limit, similarity_threshold=0.25
            )
            news_results_task = self.batch_search_news(
                all_queries, limit=news_limit, similarity_threshold=0.25
            )
            
            company_results, news_results = await asyncio.gather(
                company_results_task, news_results_task
            )
            
            # ê²°ê³¼ í†µí•© ë° ì¤‘ë³µ ì œê±°
            all_companies = {}
            all_news = []
            
            for query, companies in company_results.items():
                for company in companies:
                    company_id = company["id"]
                    if company_id not in all_companies:
                        all_companies[company_id] = company
                    else:
                        # ìœ ì‚¬ë„ê°€ ë” ë†’ì€ ê²½ìš° ì—…ë°ì´íŠ¸
                        if company["similarity"] > all_companies[company_id]["similarity"]:
                            all_companies[company_id] = company
            
            for query, news_list in news_results.items():
                all_news.extend(news_list)
            
            # ë‰´ìŠ¤ ì¤‘ë³µ ì œê±° ë° ì •ë ¬
            seen_news = set()
            unique_news = []
            for news in sorted(all_news, key=lambda x: x["similarity"], reverse=True):
                news_key = (news["title"], news["company_id"])
                if news_key not in seen_news:
                    seen_news.add(news_key)
                    unique_news.append(news)
                    if len(unique_news) >= news_limit * 2:
                        break
            
            context["companies"] = list(all_companies.values())
            context["news"] = unique_news[:news_limit * 2]
            
            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            embedding_stats = self.batch_embedding_service.get_service_stats()
            context["metadata"].update({
                "companies_found": len(context["companies"]),
                "news_found": len(context["news"]),
                "embedding_cache_hits": embedding_stats.get("cache", {}).get("hit_count", 0),
                "total_cost": embedding_stats["total_cost"],
                "cache_hit_rate": embedding_stats.get("cache", {}).get("hit_rate", 0)
            })
            
            self.logger.info(
                f"ğŸ¯ Optimized search completed | "
                f"Companies: {len(context['companies'])} | "
                f"News: {len(context['news'])} | "
                f"Cost: ${embedding_stats['total_cost']:.6f} | "
                f"Cache hit rate: {context['metadata']['cache_hit_rate']:.1f}%"
            )
            
        except Exception as e:
            self.logger.error(f"ì¸ì¬ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        return context
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.session:
            self.session.close()
    
    def get_optimization_stats(self) -> Dict[str, Any]:
        """ë²¡í„° ê²€ìƒ‰ ìµœì í™” í†µê³„"""
        return {
            "embedding_service": self.batch_embedding_service.get_service_stats(),
            "database_connection": "active" if self.session else "closed"
        }


# ê¸°ì¡´ íŒ©í† ë¦¬ í´ë˜ìŠ¤ë“¤ ìœ ì§€ (í˜¸í™˜ì„±)
class VectorSearchFactory:
    """ë²¡í„° ê²€ìƒ‰ ì—”ì§„ íŒ©í† ë¦¬"""
    
    @staticmethod
    def create_search_engine() -> VectorSearchEngine:
        """ë²¡í„° ê²€ìƒ‰ ì—”ì§„ ìƒì„±"""
        return VectorSearchEngine()


class VectorSearchManager:
    """ë²¡í„° ê²€ìƒ‰ ê´€ë¦¬ì (ê°œì„ ë¨)"""
    
    def __init__(self):
        self.search_engine = None
    
    def get_search_engine(self) -> VectorSearchEngine:
        """ë²¡í„° ê²€ìƒ‰ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (Lazy Loading)"""
        if self.search_engine is None:
            self.search_engine = VectorSearchFactory.create_search_engine()
        return self.search_engine
    
    def search_talent_context(self, talent_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì¸ì¬ ë°ì´í„° ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ë¹„ë™ê¸° ë˜í¼)"""
        import asyncio
        engine = self.get_search_engine()
        
        # ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰
        try:
            loop = asyncio.get_event_loop()
            return loop.run_until_complete(
                engine.search_talent_related_context(talent_data)
            )
        except RuntimeError:
            # ìƒˆ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„±
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                return loop.run_until_complete(
                    engine.search_talent_related_context(talent_data)
                )
            finally:
                loop.close()
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.search_engine:
            self.search_engine.close()
            self.search_engine = None 